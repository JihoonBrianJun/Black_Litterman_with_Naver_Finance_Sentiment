{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c890c714",
   "metadata": {
    "id": "xYuBVCXrHIcH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b1ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data file containing the info from Naver Finance\n",
    "\n",
    "df = pd.read_csv(os.path.join(os.getcwd(),'all.csv')).reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f02db946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the \"title\" column of all.csv as title_df\n",
    "# Most of the titles end with \"[n]\" where n is the number of replies that the thread has\n",
    "# Since it is redundant info as of now, we drop such info at the end of each title\n",
    "title_df = pd.DataFrame(df['title'].dropna().apply(lambda x: x.split('[')[0]))\n",
    "\n",
    "# To use the KOBERT model, we need to input the data in tsv format\n",
    "title_df.to_csv(os.path.join(os.getcwd(),'title.txt'),sep='\\t')\n",
    "\n",
    "title_list = title_df['title'].to_list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "051898c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-29 14:03:34--  http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_train.txt\n",
      "Resolving skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)... 52.219.58.126\n",
      "Connecting to skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)|52.219.58.126|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14628807 (14M) [text/plain]\n",
      "Saving to: ‘.cache/ratings_train.txt’\n",
      "\n",
      ".cache/ratings_trai 100%[===================>]  13.95M  70.6MB/s    in 0.2s    \n",
      "\n",
      "2022-12-29 14:03:35 (70.6 MB/s) - ‘.cache/ratings_train.txt’ saved [14628807/14628807]\n",
      "\n",
      "--2022-12-29 14:03:35--  http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_test.txt\n",
      "Resolving skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)... 52.219.58.126\n",
      "Connecting to skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)|52.219.58.126|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4893335 (4.7M) [text/plain]\n",
      "Saving to: ‘.cache/ratings_test.txt’\n",
      "\n",
      ".cache/ratings_test 100%[===================>]   4.67M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2022-12-29 14:03:35 (31.8 MB/s) - ‘.cache/ratings_test.txt’ saved [4893335/4893335]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This research leverages on the pre-trained word embeddings from\n",
    "# Naver Sentiment Movie Corpus project (https://github.com/e9t/nsmc) based on KOBERT\n",
    "# It consists of 100K positive and 100K negative reviews from Naver Movie\n",
    "\n",
    "!wget -O .cache/ratings_train.txt http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_train.txt\n",
    "!wget -O .cache/ratings_test.txt http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d821967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can verify that NSMC corpus consists of 75% of train data and 25% of test data\n",
    "# Therefore, additional word inputs in this research will maintain the same train-test ratio\n",
    "pd.read_csv('.cache/ratings_train.txt',sep='\\t').shape[0] / pd.read_csv('.cache/ratings_test.txt',sep='\\t').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5394ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>물 탄 나를 칭찬한다!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>안티들은 왜이리 차트차트</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>지엠 2025년 EV 100만대?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>참 어이없네</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>포스코 케미칼, 세계 전기차 배터리 최강...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title  signal\n",
       "0               물 탄 나를 칭찬한다!        0\n",
       "1              안티들은 왜이리 차트차트        0\n",
       "2          지엠 2025년 EV 100만대?       0\n",
       "3                      참 어이없네       0\n",
       "4  포스코 케미칼, 세계 전기차 배터리 최강...        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directly classifying Naver Finance sentiments based on NSMC corpus may lead to incomplete results\n",
    "# So I designate several intuitive and definite positive/neagtive keywords\n",
    "# and classify each \"titles\" as positive thread if\n",
    "# it contains any positive keyword and does not contain negative keywords\n",
    "# and classify each \"titles\" as negative thread if\n",
    "# it contains any negative keyword and does not contain positive keywords\n",
    "# Other threads are classified in the subsequent process\n",
    "\n",
    "positive_keyword = ['매수','오르','오른','오를','상승','폭등','산다','안판다','안 판다','안내릴','안 내릴','안내린','안 내린','안내리','안 내리','벌']\n",
    "negative_keyword = ['매도','내리','내린','내릴','하락','폭락','판다','안산다','안 산다','안오를','안 오를','안오른','안 오른','안오르','안 오르','비싸','락','떨어','잃','공매']\n",
    "\n",
    "# Thread with signal=1 is positive, signal=-1 is negative, and signal=0 is indefinite\n",
    "title_df['signal'] = title_df['title'].str.contains('|'.join(positive_keyword))*1+title_df['title'].str.contains('|'.join(negative_keyword))*(-1)\n",
    "title_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5da590ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5123/4179755693.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nonneutral_df['signal'].replace(-1,0,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Extract positive/negative threads based on the above criteria\n",
    "# and change the signal value of negative threads from -1 to 0\n",
    "\n",
    "nonneutral_df = title_df[title_df['signal']!=0]\n",
    "nonneutral_df['signal'].replace(-1,0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dd51d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle nonneutral_df\n",
    "nonneutral_df = nonneutral_df.sample(frac=1).reset_index().drop('index',axis=1)\n",
    "\n",
    "# Split nonentural_df into the train and test dataset\n",
    "nonneutral_train = nonneutral_df.loc[:nonneutral_df.shape[0]//4*3]\n",
    "nonneutral_test = nonneutral_df.loc[nonneutral_df.shape[0]//4*3+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce0f61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire/train/test dataset of nonneutral df, respectively\n",
    "\n",
    "nonneutral_df.to_csv('nonneutral.txt',sep='\\t')\n",
    "nonneutral_train.to_csv('nonneutral_train.txt',sep='\\t')\n",
    "nonneutral_test.to_csv('nonneutral_test.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b44b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the nonneutral_train with NSMC train dataset\n",
    "# and save it as train_df and train_all.txt (tsv format)\n",
    " \n",
    "train_df1 = pd.read_csv(os.path.join(os.getcwd(),'nonneutral_train.txt'),sep='\\t').rename(columns={'Unnamed: 0':'id','title':'document','signal':'label'})\n",
    "train_df2 = pd.read_csv('.cache/ratings_train.txt',sep='\\t')\n",
    "train_df = pd.concat([train_df1,train_df2],axis=0).sample(frac=1).reset_index().drop('index',axis=1)\n",
    "\n",
    "train_df.to_csv(os.path.join(os.getcwd(),'train_all.txt'),sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eeaf7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the nonneutral_test with NSMC test dataset\n",
    "# and save it as test_df and test_all.txt (tsv format)\n",
    "\n",
    "test_df1 = pd.read_csv(os.path.join(os.getcwd(),'nonneutral_test.txt'),sep='\\t').rename(columns={'Unnamed: 0':'id','title':'document','signal':'label'})\n",
    "test_df2 = pd.read_csv('.cache/ratings_test.txt',sep='\\t')\n",
    "test_df = pd.concat([test_df1,test_df2],axis=0).sample(frac=1).reset_index().drop('index',axis=1)\n",
    "\n",
    "test_df.to_csv(os.path.join(os.getcwd(),'test_all.txt'),sep='\\t',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jjh1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "15f4aacd9556265f1615cc73c631931044efcc45c198588ea5b6a55eacfa69f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
